# Tarea 03 ‚Äì M√©todos de Gran Escala Best Practices

Esta carpeta contiene la **Tarea 03** del curso **M√©todos de Gran Escala**.  
El objetivo de esta tarea es implementar un **pipeline reproducible de datos y modelado**, siguiendo buenas pr√°cticas de ingenier√≠a de datos y MLOps.

---

## Estructura del proyecto

```
tarea-03/
‚îÇ
‚îú‚îÄ‚îÄ notebooks/          # Notebooks de exploraci√≥n, EDA y prototipos
‚îÇ
‚îú‚îÄ‚îÄ data/               # Datos del proyecto
‚îÇ   ‚îú‚îÄ‚îÄ raw/            # Datos originales (sin modificar)
‚îÇ   ‚îú‚îÄ‚îÄ prep/           # Datos preparados para modelado
‚îÇ   ‚îú‚îÄ‚îÄ inference/      # Datos para inferencia batch
‚îÇ   ‚îî‚îÄ‚îÄ predictions/    # Salidas de predicci√≥n batch
‚îÇ
‚îú‚îÄ‚îÄ src/                # C√≥digo productivo (scripts)
‚îÇ   ‚îú‚îÄ‚îÄ etl.py          # Pipeline de extracci√≥n y preparaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ features.py     # Feature engineering
‚îÇ   ‚îú‚îÄ‚îÄ train.py        # Entrenamiento del modelo
‚îÇ   ‚îî‚îÄ‚îÄ predict.py      # Inferencia batch
‚îÇ
‚îú‚îÄ‚îÄ artifacts/          # Artefactos generados
‚îÇ   ‚îú‚îÄ‚îÄ models/         # Modelos entrenados
‚îÇ   ‚îú‚îÄ‚îÄ reports/        # Reportes y gr√°ficos
‚îÇ   ‚îî‚îÄ‚îÄ metrics/        # M√©tricas y evaluaciones
‚îÇ
‚îú‚îÄ‚îÄ pyproject.toml      # Definici√≥n de dependencias
‚îú‚îÄ‚îÄ uv.lock             # Lockfile para reproducibilidad
‚îî‚îÄ‚îÄ README.md           # Este archivo
```

## Convenios del proyecto

Este proyecto sigue una serie de **convenios est√°ndar** para asegurar orden, reproducibilidad y escalabilidad.

---

### üìÇ Organizaci√≥n de carpetas

- **`notebooks/`**
  - Uso exclusivo para:
    - EDA
    - An√°lisis exploratorio
    - Pruebas y prototipos
  - No debe contener l√≥gica productiva final.

- **`src/`**
  - Contiene √∫nicamente **c√≥digo productivo**.
  - Cada script debe ser:
    - Reproducible
    - Ejecutable
    - Independiente del entorno interactivo.
  - No se ejecutan notebooks en producci√≥n.

- **`data/`**
  - `raw/`: datos originales (solo lectura).
  - `prep/`: datos transformados y listos para modelado.
  - `inference/`: datos usados para predicci√≥n batch.
  - `predictions/`: resultados de inferencia.

- **`artifacts/`**
  - Modelos entrenados
  - Reportes
  - Gr√°ficos
  - M√©tricas
  - Cualquier salida generada por el pipeline

---

## Modelo de datos (ventas_pred)

Este es el modelo de datos utilizado en el pipeline de **ventas_pred** (ETL + agregaci√≥n mensual con lags):

![Modelo de Datos ventas_pred](../../reports/Modelo_de_Datos.png)

### üß™ Manejo de datos

- Los datos **no se versionan** en Git.
- Solo se versiona la **estructura de carpetas**.
- El formato est√°ndar para datos intermedios es **Parquet**.
- Los CSV solo se permiten en `raw/` si vienen de la fuente original.

---

### üì¶ Dependencias y entorno

- El proyecto utiliza **`uv`** para manejo de dependencias.
El proyecto incluye:
  - `pyproject.toml`
  - `uv.lock`
  
Principales librer√≠as:

- boto3 (>= 1.42.34)
- jupyterlab (>= 4.5.2)
- kaggle (>= 1.8.3)
- lightgbm (>= 4.6.0)
- matplotlib (>= 3.10.8)
- numpy (>= 2.4.1)
- pandas (>= 3.0.0)
- pyarrow (>= 23.0.0)
- scikit-learn (>= 1.8.0)


### Instalaci√≥n del ambiente

Desde la carpeta de la tarea/proyecto:

bash
uv sync

Este comando:
	‚Ä¢	Crea el entorno virtual si no existe
	‚Ä¢	Instala las dependencias definidas en pyproject.toml
	‚Ä¢	Garantiza reproducibilidad usando uv.lock

## Detalle de la ejecuci√≥n del proyecto

Esta secci√≥n describe **c√≥mo ejecutar el pipeline del proyecto** de forma correcta y reproducible, siguiendo los convenios definidos.

---

### üìç Punto de partida

Todos los comandos deben ejecutarse **desde la ra√≠z de la tarea**, por ejemplo:

bash
cd tareas/tarea-03
uv sync
uv run python src/etl.py
uv run python src/features.py
uv run python src/train.py
uv run python src/predict.py

Flujo recomendado: 

raw ‚Üí etl ‚Üí prep ‚Üí features ‚Üí train ‚Üí model ‚Üí predict ‚Üí predictions

## Autor

	‚Ä¢	Jos√© Antonio Esparza
	‚Ä¢	Gustavo Pardo

- Repositorio desarrollado como parte del curso M√©todos de Gran Escala.
